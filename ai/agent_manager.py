import os
import json
from dotenv import load_dotenv
from mistralai import Mistral
from precheck import TicketPrechecker
from queryanalyser import analyse_query
from solutionfinder import solution_finder
from deterministic_evaluation import DeterministicEvaluator
from response_composer import compose_response

# Load environment variables
load_dotenv()

class AgentManager:
    def __init__(self):
        self.api_key = os.getenv("MISTRAL_API_KEY")
        if not self.api_key:
            raise ValueError("MISTRAL_API_KEY not found in .env file")
        
        self.client = Mistral(api_key=self.api_key)
        self.prechecker = TicketPrechecker()
        self.evaluator = DeterministicEvaluator()
        self.model = "mistral-large-latest"
        self.confidence_threshold = 0.6
        
        # Mock Knowledge Base
        self.knowledge_base = [
            {"id": "kb1", "content": "Pour r√©initialiser votre mot de passe, cliquez sur 'Mot de passe oubli√©' sur la page de connexion."},
            {"id": "kb2", "content": "Nos d√©lais de livraison standard sont de 3 √† 5 jours ouvrables."},
            {"id": "kb3", "content": "Le support technique est disponible de 9h √† 18h, du lundi au vendredi."},
            {"id": "kb4", "content": "Vous pouvez retourner un article dans les 30 jours suivant l'achat s'il est dans son emballage d'origine."}
        ]

    def process_ticket(self, ticket_content):
        """
        Orchestrate the full ticket processing pipeline.
        """
        try:
            print("\n" + "="*50)
            print("D√âBUT DU TRAITEMENT DU TICKET")
            print("="*50)

            # Step 1: Precheck
            print("\n[√âtape 1] Pr√©-v√©rification...")
            precheck_results = self.prechecker.run_precheck(ticket_content)
            
            if not precheck_results["passed"]:
                print(f"‚ùå √âchec de la pr√©-v√©rification : {', '.join(precheck_results['reason'])}")
                return {
                    "status": "rejected",
                    "reason": precheck_results["reason"],
                    "details": precheck_results
                }
            
            print("‚úÖ Pr√©-v√©rification r√©ussie.")
            if precheck_results["has_sensitive_data"]:
                print("‚ö†Ô∏è Donn√©es sensibles d√©tect√©es et masqu√©es.")
                print(f"üîç Contenu s√©curis√© : {precheck_results['masked_content']}")

            # Use masked content for the AI agent
            content_to_process = precheck_results["masked_content"]
            
            # Step 2: Query Analyser (LLM CALL)
            print("\n[√âtape 2] Analyse de la requ√™te...")
            analysis = analyse_query(content_to_process)
            print(f"üìù R√©sum√© : {analysis.get('summary')}")
            print(f"Cat√©gorie : {analysis.get('category')}")
            print(f"üîë Mots-cl√©s : {', '.join(analysis.get('keywords', []))}")
            
            # Check if the query is in scope for the company
            if not analysis.get("is_in_scope", True):
                print("üö´ Requ√™te hors sujet (Hors p√©rim√®tre Doxa).")
                out_of_scope_msg = "D√©sol√©, je ne peux r√©pondre qu'aux questions li√©es √† Doxa et √† nos services techniques. Votre demande semble √™tre hors sujet."
                print("\n" + "-"*30)
                print("R√âPONSE FINALE :")
                print(out_of_scope_msg)
                print("-"*30)
                return {
                    "status": "rejected",
                    "reason": "Out of scope",
                    "final_response": out_of_scope_msg,
                    "analysis": analysis,
                    "precheck": precheck_results
                }

            # Optimization logic
            query_for_rag = content_to_process
            if not analysis.get("is_sufficient", True):
                print("‚ö†Ô∏è Requ√™te jug√©e trop courte ou vague. Optimisation en cours...")
                query_for_rag = analysis.get("optimized_query", content_to_process)
                print(f"üîç Requ√™te optimis√©e : {query_for_rag}")
            else:
                # Even if sufficient, we can use the optimized version if it exists for better synonyms
                query_for_rag = analysis.get("optimized_query", content_to_process)

            # Step 3: Solution Finder (LLM CALL - RAG)
            print("\n[√âtape 3] Recherche de solution (RAG)...")
            rag_result = solution_finder(query_for_rag, category=analysis.get("category"))
            
            if rag_result.get("fallback_used"):
                print("‚ÑπÔ∏è Note : La recherche a √©t√© √©tendue √† d'autres cat√©gories car aucun document pertinent n'a √©t√© trouv√© dans la cat√©gorie initiale.")

            proposed_answer = rag_result["answer"]
            print(f"üí° Solution propos√©e : {proposed_answer[:100]}...")
            
            # Get context used for evaluation
            context_used = "\n".join([doc["content"] for doc in rag_result["used_documents"]])
            # Get the best retrieval score (similarity)
            best_retrieval_score = rag_result["used_documents"][0].get("score", 0.5) if rag_result["used_documents"] else 0.0

            # Step 4: Deterministic Evaluation (Hugging Face model)
            print("\n[√âtape 4] √âvaluation de la confiance...")
            evaluation = self.evaluator.evaluate(
                query=query_for_rag,
                context=context_used,
                response=proposed_answer,
                retrieval_score=best_retrieval_score,
                threshold=self.confidence_threshold
            )
            print(f"üìä Score de confiance global : {evaluation['confidence_score']}")
            print(f"   - Pertinence (Doc vs Question) : {evaluation['relevance_score']}")
            print(f"   - Fid√©lit√© (R√©ponse vs Doc) : {evaluation['faithfulness_score']}")
            print(f"   - Sentiment d√©tect√© : {evaluation.get('sentiment', 'neutral')}")
            
            # Step 5 & 5.1: Logic based on confidence
            if evaluation["confidence_score"] >= self.confidence_threshold and not evaluation.get("is_refusal"):
                print(f"‚úÖ Confiance √©lev√©e. Composition de la r√©ponse finale...")
                # Step 5: Response Composer (LLM)
                final_response_data = compose_response(content_to_process, proposed_answer, evaluation)
                
                print("\n" + "-"*30)
                print("R√âPONSE FINALE :")
                print(final_response_data["final_response"])
                print("-"*30)

                return {
                    "status": "success",
                    "final_response": final_response_data["final_response"],
                    "confidence": evaluation["confidence_score"],
                    "analysis": analysis,
                    "precheck": precheck_results,
                    "proposed_answer": proposed_answer
                }
            else:
                # Step 5.1: Orient to specialist human agent (NO LLM)
                if evaluation.get("is_refusal"):
                    print(f"‚ö†Ô∏è L'IA n'a pas trouv√© de r√©ponse dans les documents. Orientation vers un agent humain...")
                    reason = "No information found in KB"
                else:
                    print(f"‚ö†Ô∏è Confiance faible ({evaluation['confidence_score']}). Orientation vers un agent humain...")
                    reason = f"Low confidence score ({evaluation['confidence_score']})"
                
                result = self.orient_to_human(analysis, precheck_results)
                result["reason"] = reason
                print(f"üë®‚Äçüíº Orient√© vers : {result['orientation']['target_department']}")
                return result

        except Exception as e:
            print(f"‚ùå Erreur critique lors du traitement : {e}")
            # In case of any unexpected error, escalate to human
            error_analysis = {"summary": "Error during processing", "agent_role": "agt_tech"}
            return self.orient_to_human(error_analysis, {"passed": True, "masked_content": ticket_content})

    def orient_to_human(self, analysis, precheck_results):
        """
        Orient the ticket to a specialist human agent using summary and keywords.
        """
        summary = analysis.get("summary", "N/A")
        keywords = analysis.get("keywords", [])
        agent_role = analysis.get("agent_role", "agt_tech") # Default to tech if not specified
        
        # Logic to "orient" could be more complex, but here we just return the info
        return {
            "status": "escalated",
            "reason": "Low confidence in AI response",
            "orientation": {
                "summary": summary,
                "keywords": keywords,
                "target_department": agent_role
            },
            "precheck": precheck_results
        }

    def handle_rating(self, ticket_id, stars, analysis, precheck_results):
        """
        Handle client rating. If <= 2 stars, escalate to human.
        """
        if stars <= 2:
            print(f"Rating low ({stars} stars). Escalating to human...")
            return self.orient_to_human(analysis, precheck_results)
        else:
            return {"status": "completed", "message": "Thank you for your feedback!"}

if __name__ == "__main__":
    from solutionfinder import ingest_pdf_to_chroma
    manager = AgentManager()
    
    while True:
        print("\n" + "-"*50)
        ticket = input("Veuillez saisir votre message (ou 'exit' pour quitter) : ")
        
        if ticket.lower() in ['exit', 'quit']:
            print("Fermeture du syst√®me. Au revoir !")
            break
            
        if ticket.startswith("/ingest "):
            # Improved parsing to handle spaces in category
            content = ticket.replace("/ingest ", "").strip()
            if content.startswith('"'):
                # Handle quoted path
                end_quote = content.find('"', 1)
                pdf_path = content[1:end_quote]
                category = content[end_quote+1:].strip() or "general"
            else:
                parts = content.split(" ", 1)
                pdf_path = parts[0]
                category = parts[1].strip() if len(parts) > 1 else "general"
            
            if os.path.exists(pdf_path):
                try:
                    ingest_pdf_to_chroma(pdf_path, category=category)
                except Exception as e:
                    print(f"‚ùå Erreur lors de l'ingestion : {e}")
            else:
                print(f"‚ùå Fichier introuvable : {pdf_path}")
            continue

        if not ticket.strip():
            continue
            
        try:
            result = manager.process_ticket(ticket)
            
            # Optionnel : Demander une √©valuation si le traitement a r√©ussi
            if result["status"] == "success":
                try:
                    print("\nComment √©valueriez-vous cette r√©ponse ? (1-5 √©toiles)")
                    stars = input("√âtoiles : ")
                    if stars.isdigit():
                        stars = int(stars)
                        rating_result = manager.handle_rating("ticket_id", stars, result["analysis"], result["precheck"])
                        if rating_result["status"] == "escalated":
                            print(f"\n‚ö†Ô∏è Suite √† votre note, le ticket a √©t√© orient√© vers : {rating_result['orientation']['target_department']}")
                        else:
                            print(f"\n‚úÖ {rating_result['message']}")
                except Exception as e:
                    print(f"Erreur lors de l'√©valuation : {e}")
        except Exception as e:
            print(f"\n‚ùå Une erreur inattendue est survenue : {e}")
            print("Veuillez v√©rifier votre connexion internet et r√©essayer.")
